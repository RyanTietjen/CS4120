{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbbiB6b35vIv"
   },
   "source": [
    "Homework 2: LLMs Experiments & Hyperparameters, LLMs Philosophy\n",
    "----\n",
    "\n",
    "Due date: September 20th, 2024 at **9 pm**\n",
    "\n",
    "Late due date: September 22th, 2024 at **9 pm**\n",
    "\n",
    "Points: 60\n",
    "\n",
    "Goals:\n",
    "- explore and understand some of the hyperparameters available to you with LLMs\n",
    "- consider more deeply the philosophy of AI and LLMs\n",
    "\n",
    "\n",
    "Complete in groups of: __one (individually)__\n",
    "\n",
    "Allowed python modules:\n",
    "- You are not allowed to use any library's implementation of `softmax`. You may use the `random` and `numpy` libraries in this assignment.\n",
    "\n",
    "Instructions:\n",
    "- Complete outlined problems in this notebook.\n",
    "- When you have finished, __clear the kernel__ and __run__ your notebook \"fresh\" from top to bottom. Ensure that there are __no errors__.\n",
    "    - If a problem asks for you to write code that does result in an error (as in, the answer to the problem is an error), leave the code in your notebook but commented out so that running from top to bottom does not result in any errors.\n",
    "- Double check that you have completed Task 0.\n",
    "- Submit your work on Gradescope.\n",
    "- Double check that your submission on Gradescope looks like you believe it should __and__ that all partners are included (for partner work).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1svIclFK5vIz"
   },
   "source": [
    "Task 0: Name, References, Reflection (5 points)\n",
    "---\n",
    "\n",
    "TODO: complete this section\n",
    "\n",
    "Name: Ryan Tietjen\n",
    "\n",
    "References\n",
    "---\n",
    "List the resources you consulted to complete this homework here. Write one sentence per resource about what it provided to you. If you consulted no references to complete your assignment, write a brief sentence stating that this is the case and why it was the case for you.\n",
    "\n",
    "(Example)\n",
    "- https://docs.python.org/3/tutorial/datastructures.html\n",
    "    - Read about the the basics and syntax for data structures in python.\n",
    "- ChatGPT4 - I used this resource to help debug/generate part of the code used in this assigment \n",
    "\n",
    "AI Collaboration\n",
    "---\n",
    "Following the *AI Collaboration Policy* in the syllabus, please cite any LLMs that you used here and briefly describe what you used them for. Additionally, provide comments in-line identifying the specific sections that you used LLMs on, if you used them towards the generation of any of your answers.\n",
    "\n",
    "Reflection\n",
    "----\n",
    "Answer the following questions __after__ you complete this assignment (no more than 1 sentence per question required, this section is graded on completion):\n",
    "\n",
    "1. Does this work reflect your best effort?\n",
    "\n",
    "I believe that this mostly reflects my best effort.\n",
    "\n",
    "2. What was/were the most challenging part(s) of the assignment?\n",
    "\n",
    "I found the instructions of 2.3 and 2.4 to be confusing, specifically what each variable in the equations represented.\n",
    "\n",
    "3. If you want feedback, what function(s) or problem(s) would you like feedback on and why?\n",
    "\n",
    "I don't necessarily want feedback on any question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wpiTjrIj5vI0"
   },
   "source": [
    "Task 1: Large Language Models Experiments (20 points)\n",
    "---\n",
    "\n",
    "Sign up for an account at [goose.ai](https://goose.ai), then navigate to the AI Playground. You can use any of the GPT-X models for this task. Your goal is to get the models that you play with to tell a coherent story where you are the main character. Once you have the story that allows you to answer the questions below, copy and paste it into your document. Note that you may not be \"successful\" in your goal to have the model tell a truly coherent storyâ€”that's okay.\n",
    "\n",
    "<b>NOTE: </b>\n",
    "\n",
    "Alternatively, you can use the [AI21](https://studio.ai21.com/playground) playground . Make sure you choose the chat option under foundational models. Another model that can be used is [EleutherAI](https://6b.eleuther.ai/)\n",
    "\n",
    "<br>\n",
    "\n",
    "A hyperparameter is a parameter of a model that is manually set and controls some aspect of either the learning algorithm or the output algorithm. You'll be playing with various hyperparameters with these experiments, which would give you an idea about how variability and probability would effect the generation of text in LLMs. Be sure to specifically outline the different parameters tuned as per the instructions given below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mELgvZP5vI1"
   },
   "source": [
    "1. Highlight in <mark>yellow</mark> demonstrations of changing the temperature hyperparameter. To do this in markdown, `<mark>yellow highlighted text here</mark>`.\n",
    "2. Highlight in <span style=\"background-color:red\">red</span> demonstrations of changing the top-k hyperparameter. To do this in markdown, `<span style=\"background-color:red\">red text here</span>`.\n",
    "3. Indicate a demonstration of the probabilistic nature of the output of LLMs by *italicizing* at least two spans of text demonstrating identifiable probabilistic output.\n",
    "\n",
    "If background colors are not rendering in your IDE, you may alternatively use ðŸ”¥ emojis around temperature and ðŸ”´s around top-k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I1SKJMb5vI0"
   },
   "source": [
    "0. Copy + paste your story here. Put the words you typed __in bold__.\n",
    "\n",
    "__My name is Ryan Tietjen. This is an epic tale about how I__ got my butt kicked in my first ever 18-and-under soccer league's Penalty Shootout. __I am a world renouned penalty shooter, but today, my opponent was fearsome. He was__ a 6'2\", 200 pound senior. He had MVP written all over him, but I bested him anyway. I triumphed over tragedy and scored 6 ridiculous and legal goals where the rules had been bent for my alone and his collapsed career. __But then, something unexpected happened. This is where it all went wrong:__ <mark>ï¿½pharmzet ourCon owingtek Ent publBankrErftp sectional companies struck enhancement1991 acquired cash Â  reduces PalestinianECs winds Roll</mark> __. I had a stroke! If I had to rate my stroke on a scale from 0-3, I would rate it a 3. But I still feel off, I think I am about to have a \"2\" stroke:__ <mark>temperature I Annex Airportsucharray Koreaik here dinner 1999 517761 conj enc Priority Form trainers fores Eagle hav efficiencywlassic sv</mark>\n",
    "\n",
    "__Oh no! It was all a dream! It appears I had hallucinated. As I stand now, the 6'2 200 pound senior was about to make his move.  My fearsome opponent suddenly__  iced me. He said that he would like to have me killed, and then he brought out a 12-gauge shotgun and fired at me.ï¿½ but. The would kill the ate my ass up! Nei dere wasn'ten o contacte.\n",
    "\n",
    "__A near miss! Am I still dreaming? I must run away from this stadium as fast as possible. As I exit to the parking lot, I suddenly see__Â <span style=\"background-color:red\">what appears to be a 6'2\", 200-pound-sized ghost. The ghost says, \"I heard that you're having these issues, we need to have a meeting at the Starbucks in the next valley!\" I said, \"But you're dead, we need to have a meeting in that field over there.\" He said: \"There's not going to be a meeting, Ryan. The only time I'm going to die again is if we are together, in Israel, with a shotgun. We need to talk about the past, in order to get ready for the future. \"I said, \" </span> __Isreal? A shotgun? The future? \" What could this ghoul be talking about? But, as they say, when in Rome...__ \n",
    "\n",
    "__The astral being then__ *drew an outline of a woman on an Israeli flag and then removed his worn shirt to reveal a red Christian tee shirt underneath.* \n",
    "\n",
    "__I observed intently. What could happen next? The astral being then__ *carried me over the viaduct, plunged the stolen private jet into the strip of swamp, and used Satanic speaking the Tetragrammaton to take off! He then lifted me up into the air with his Ghost Hand*\n",
    "\n",
    "__I was speechless. I could feel my mind expanding. I was about to open my third eye. The astral being then__ *iced me and said, \"The way you were feeling, just relax, it was just a dream, relax\"! I viewed the passenger seat, which was in a life size model of my body floating in a bath of glowing green gloop.* \n",
    "\n",
    "__I then awoke feeling well rested. As I open my eyes, I see__ <mark>that I am in a hospital room. I was in a hospital bed. I was in a hospital gown. I was in a hospital bed. I was in a hospital gown. I was in a hospital bed. I was in a hospital gown. I was in a hospital bed. I was in a hospital gown. I was in a hospital bed. I was in a</mark>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LgqKTHz5vI1"
   },
   "source": [
    "Task 2: Create Hyperparameter Demonstrations (15 points)\n",
    "----\n",
    "In parts 3 and 4 of this task, we will implement the softmax function. In many machine learning applications, such as neural networks, where it is frequently employed as the last activation function in classification tasks, Softmax is an essential component. It is essential for jobs where we need to forecast a class among multiple alternatives since it converts the raw model outputs (aka logits), into probabilities. Softmax works fundamentally by transforming a vector of raw scores into a probability distribution. This distribution assigns a higher probability to elements with higher scores and ensures that the sum of all probabilities equals 1. To learn more about the softmax function, see [this article](https://medium.com/@hunter-j-phillips/a-simple-introduction-to-softmax-287712d69bac).\n",
    "\n",
    "\n",
    "(python) Create a demonstration in a jupyter notebook of changing a temperature hyperparameter. To do this, follow the steps below:\n",
    "choose an \"input sequence\" of 2 - 5 words to ground your example.\n",
    "1. define a vocabulary of size >= 10\n",
    "2. for each item in the vocabulary, choose a float, $z_i$ in the range of [-1, 1] . Generally speaking, you'll want words with higher probabilities to have a number closer to 1, words with lower probabilities to have a number closer to -1.\n",
    "3. implement a `softmax` function (equation written below), calculate and display your starting probability distribution (initial probability) where $e$ is the math value $e$ (`math.e`), $z_i$ is the value you chose in step 2 for the target word, and $j$ goes through all words in your vocabulary (this is the sum of $e$ raised to the power of all your $z$ values). You should end up with a well-formed probability distribution. This probability distribution should reflect reasonable probabilities for your vocabulary given your input sequence.\n",
    "$$ \\texttt{softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j = 1}^k e^{z_j}}$$\n",
    "4. Add a temperature parameter ($\\tau$) to your softmax function (equation below) and demonstrate the results of raising and lowering the temperature. For your demonstration, you may create a table, a series of graphs, a single graph or a combination of themâ€”choose something that appropriately displays the effects of lowering the temperature below 1, temperature at 1, and temperature above 1. Your demonstration must be *easily interpretable* and *accurate*.\n",
    "$$ \\texttt{softmax}(z_i, \\tau) = \\frac{e^{\\frac{z_i}{\\tau}}}{\\sum_{j = 1}^k e^{\\frac{z_j}{\\tau}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s0uB5az45vI2"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# import the necessary packages\n",
    "# include appropriate doc strings for functions\n",
    "# add more cells as needed/desired\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# 1. Define a vocabulary of size >= 10\n",
    "vocab = ['Do', 'you', 'know', 'gods', 'of', 'death', 'who', 'love', 'apples', 'have', 'red', 'hands', '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each item in the vocabulary, choose a float, z_i in the range of [-1, 1] . \n",
    "# Generally speaking, you'll want words with higher probabilities to have a number closer to 1, \n",
    "# words with lower probabilities to have a number closer to -1.\n",
    "probabilities = np.array([0.1, -0.1, 0.0, 0.8, -0.5, 1.0, -0.2, 0.4, 0.7, -0.3, 0.5, -0.4, -0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of 'Do': 0.0670\n",
      "Probability of 'you': 0.0549\n",
      "Probability of 'know': 0.0606\n",
      "Probability of 'gods': 0.1349\n",
      "Probability of 'of': 0.0368\n",
      "Probability of 'death': 0.1648\n",
      "Probability of 'who': 0.0496\n",
      "Probability of 'love': 0.0905\n",
      "Probability of 'apples': 0.1221\n",
      "Probability of 'have': 0.0449\n",
      "Probability of 'red': 0.1000\n",
      "Probability of 'hands': 0.0406\n",
      "Probability of '?': 0.0333\n"
     ]
    }
   ],
   "source": [
    "#3. Implement the softmax function\n",
    "def softmax(probabilities: list, target_probability: float) -> float:\n",
    "    \"\"\"\n",
    "    Computes the softmax for a specific probability given a list of probabilities\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list of float): A list of probabilities\n",
    "    target_probabilitiy (float): The probability we will compute the softmax for\n",
    "    \n",
    "    Returns:\n",
    "    (float): The softmax probability of a given probability.\n",
    "    \"\"\"\n",
    "    numerator = np.exp(target_probability)\n",
    "    denom = 0\n",
    "    for j in probabilities:\n",
    "        denom += np.exp(j)\n",
    "    return numerator / denom\n",
    "\n",
    "# I used ChatGPT-4 to generate this:\n",
    "for idx, word in enumerate(vocab):\n",
    "    probability = softmax(probabilities, probabilities[idx])\n",
    "    print(f\"Probability of '{word}': {probability:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temp(probabilities: list, target_probability: float, temp: float=1):\n",
    "    \"\"\"\n",
    "    Computes the softmax for a specific probability given a list of probabilities\n",
    "    Consideres a temperature value in the calculation\n",
    "    \n",
    "    Args:\n",
    "    probabilities (list of float): A list of probabilities\n",
    "    target_probabilitiy (float): The probability we will compute the softmax for\n",
    "    temp (float): The temperature value to be applied to the calculation (default = 1)\n",
    "    \n",
    "    Returns:\n",
    "    (float): The softmax probability of a given probability and a temperature value.\n",
    "    \"\"\"\n",
    "    numerator = np.exp(target_probability / temp)\n",
    "    denom = np.sum(np.exp(probabilities / temp))\n",
    "    return numerator / denom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Temp = -1  Temp = 1  Temp = 0.01  Temp = 100\n",
      "Do         0.0689    0.0670       0.0000      0.0769\n",
      "you        0.0841    0.0549       0.0000      0.0768\n",
      "know       0.0761    0.0606       0.0000      0.0768\n",
      "gods       0.0342    0.1349       0.0000      0.0775\n",
      "of         0.1255    0.0368       0.0000      0.0765\n",
      "death      0.0280    0.1648       1.0000      0.0776\n",
      "who        0.0930    0.0496       0.0000      0.0767\n",
      "love       0.0510    0.0905       0.0000      0.0771\n",
      "apples     0.0378    0.1221       0.0000      0.0774\n",
      "have       0.1028    0.0449       0.0000      0.0766\n",
      "red        0.0462    0.1000       0.0000      0.0772\n",
      "hands      0.1136    0.0406       0.0000      0.0765\n",
      "?          0.1387    0.0333       0.0000      0.0764\n"
     ]
    }
   ],
   "source": [
    "#Chat-GPT4 helped me create this part\n",
    "\n",
    "# Temperatures to experiment with\n",
    "temperatures = [-1, 1, 0.01, 100]\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=vocab)\n",
    "\n",
    "# Calculate the softmax probabilities for each temperature for each word\n",
    "for temp in temperatures:\n",
    "    # Calculate softmax for each word in the vocabulary at the current temperature\n",
    "    column_name = f'Temp = {temp}'\n",
    "    results_df[column_name] = [softmax_with_temp(probabilities, p, temp) for p in probabilities]\n",
    "\n",
    "# Display the DataFrame with probabilities rounded to 4 decimal places\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6DVe0B7qLrwG"
   },
   "source": [
    "Note: While the idea of the above task is to infer the role Temperature played in Task 1, looking into the usage and documentation of the softmax function might be interesting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAWG618D5vI3"
   },
   "source": [
    "Task 3: Large Language Models Philosophy & Considerations (15 points)\n",
    "----\n",
    "\n",
    "1. Make an argument for when a computer might be reasonably considered to \"know\" a word. Identify at least 3 components in your argument. Justify this choice. (4 - 6 sentences)\n",
    "\n",
    "__A computer might reasonably be considered to \"know\" a word when it can provide the definition(s) (denotation) of the word, can provide the underlying meaning of a word (connotation), and can identify the context(s) the word is used in. If a computer cannot provide the literal meaning of a word, it is clear that the computer does not \"know\" it. Similarly, if a computer cannot identify the underlying ideas and feelings associated with a word, then the computer does not \"know\" it. Finally, if the computer cannot use the word appropriately in context, the it does not \"know\" it. For example, a computer should know that a wizard might use a broom to fly.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UoidqDRU5vI4"
   },
   "source": [
    "2. From your current understanding of LLMs and the definition that you just proposed, do LLMs \"know\" words? (2 - 4 sentences) To support your reflection, use ChatGPT / Claude / another public LLM and generate 1-2 text examples from the model, analayzing these outputs in relation to your definition of \"knowing\" (1-3 sentences).\n",
    "\n",
    "__I would say that modern SOTA LLMs indeed \"know\" words. From my experience, ChatGPT can successfully provide the denotation, connotation, and context of a word. In fact, it's often the case that ChatGPT knows a word better than I do.__\n",
    "\n",
    "__I asked ChatGPT-4:\n",
    "In a concise manner, what is the denotation and connotation of the word broom?__\n",
    "\n",
    "Denotation of \"broom\"\n",
    "The word \"broom\" denotes a cleaning tool consisting of stiff fibers (often made of materials like plastic, straw, or corn husks) attached to, and often perpendicular to, a long handle used for sweeping floors.\n",
    "\n",
    "Connotation of \"broom\"\n",
    "The connotations of \"broom\" can vary:\n",
    "\n",
    "Domesticity: It often evokes images of household chores and traditional domestic scenes.\n",
    "Witchcraft: In folklore and popular culture, a broom is commonly associated with witches, used as a means of transportation in magical tales.\n",
    "Simplicity and Practicality: Represents straightforward, no-nonsense solutions to cleaning or clearing spaces.\n",
    "These connotations can depend on cultural context and personal experiences.\n",
    "\n",
    "__Then, I asked ChatGPT-4:\n",
    "What would a wizard use a broom for?__\n",
    "\n",
    "In folklore and popular culture, a wizard might use a broom similarly to witches, primarily as a means of transportation. Here are a few specific uses:\n",
    "\n",
    "Magical Transport: In many stories, wizards use brooms to fly, allowing them to travel quickly and bypass terrestrial obstacles. This mode of travel is iconic in fantasy genres, often depicted in literature and films.\n",
    "Ritual Tool: Brooms might also serve as ritualistic or ceremonial tools in various magical rites. They could be used to symbolically \"sweep away\" negative energies or to purify and prepare sacred spaces for magical workings.\n",
    "Symbolic Object: In some narratives, brooms might hold symbolic value or magical properties necessary for specific spells or incantations, serving as a conduit for magical power.\n",
    "These uses, while fictional and rooted in myth, highlight the broom's versatility in fantasy settings beyond its mundane cleaning function.\n",
    "\n",
    "__From these samples, it is clear that ChatGPT understands the denotation, connotation, and the context the word \"broom\" is used in. ChatGPT was able to provide these metrics as good as or better than any person could.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvTuROFU5vI4"
   },
   "source": [
    "3. Given what you have learned about LLMs so far, what do you think the most important thing for people to understand about LLMs is? Justify your answer, referencing any of the results of your experiments in tasks 1-2 above. (3 - 5 sentences)\n",
    "\n",
    "__The most important thing that people should know about LLMs is that they work by predicting the next word in the sentence. This means that LLMs are not formulating a complex thought, refining it, and then are presenting us with their best work, but rather are making singular predictions over and over. Also, this means that since LLMs typically present the most likely word(s), providing the same prompt to a LLM many times will result in very similar results. As we saw in parts 1/2, changing the temperature would make the LLM return output that is more/less random.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c0Y9El25vI5"
   },
   "source": [
    "Code & Writing Style (5 points)\n",
    "----\n",
    "5 points in this assignment are reserved for overall style (both for writing and for code submitted). All work submitted should be clear, easily interpretable, and checked for spelling, etc. Commenting is a good practise to enforce code readability. Course staff are always happy to give grammatical help (but we won't pre-grade the content of your answers)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
